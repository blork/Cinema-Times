name: Scrape Cinema Times

on:
  # Run automatically every 6 hours
  schedule:
    - cron: '0 */6 * * *'  # Every 6 hours
  
  # Allow manual triggering
  workflow_dispatch:
  
  # Run on pushes to master (for testing)
  push:
    branches: [ master ]

permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment
concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  scrape-and-build:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run cinema scraper with RT scores
      env:
        OMDB_API_KEY: ${{ secrets.OMDB_API_KEY }}
      run: |
        echo "ðŸŽ­ Starting cinema scraper..."
        python scraper.py
        echo "âœ… Scraping complete"
        
    - name: Display scraping results
      run: |
        echo "ðŸ“Š Scraping Statistics:"
        echo "JSON file size: $(wc -c < cinema-times.json) bytes"
        echo "Number of showings: $(jq '.showings | length' cinema-times.json)"
        echo "Unique movies: $(jq '.showings | map(.title) | unique | length' cinema-times.json)"
        echo "Last updated: $(jq -r '.last_updated' cinema-times.json)"
        
    - name: Setup Pages
      uses: actions/configure-pages@v4
      
    - name: Upload artifact
      uses: actions/upload-pages-artifact@v3
      with:
        path: '.'

  deploy:
    needs: scrape-and-build
    runs-on: ubuntu-latest
    
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
      
    steps:
    - name: Deploy to GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v4